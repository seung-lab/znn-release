[parameters]
# general
# specification file of network architecture
fnet_spec = ../networks/N4.znn
# file of data spec
fdata_spec = ../dataset/ISBI2012/dataset.spec
# number of threads. if <=0, the thread number will be equal to
# the number of concurrent threads supported by the implementation.
num_threads = 0
# data type of arrays: float32 or float64
dtype = float32
# type of network output: boundary or affinity
out_type = boundary
# Whether to record config and log files
logging = no

# train
# saved network file name. will automatically add iteration number
# saved file name example: net_21000.h5, net_current.h5
# the net_current.h5 will always be the latest network
train_net = ../experiments/ISBI/N4/net.h5
# sample ID range for train
# example: 2-3,7
train_range = 1
# sample ID range for validate/test during training
# example: 1,4-6,8
test_range = 1
# dense output size of one forward pass: z,y,x
# large output size can reduce the computational redundency
# this parameter affects the memory consumption a lot.
# keep an eye to the memory, if it occupies too much memory, reduce this outsz
train_outsz = 1,100,100

# mode: fft, direct, optimize
# if optimize, znn will choose direct convolution or fft for each layer.
# optimize will get the best performance, but it takes a few minutes at the beginning.
# it is suggested to use fft for fast testing and forward pass, and use optimize for long-time training
train_conv_mode = fft

# cost function: square_loss, binomial_cross_entropy, softmax_loss, auto
# auto mode will match the out_type: boundary-softmax_loss, affinity-binomial_cross_entropy
cost_fn = auto
# use malis weighting of gradient
# Maximin affinity learning of image segmentation
# http://papers.nips.cc/paper/3887-maximin-affinity-learning-of-image-segmentation
# For normal training, you don't need this.
is_malis = no
# type of malis normalization:
# none: no normalization,
# frac: segment fractional normalization
# num : normalized by N (number of nonboundary voxels)
# pair: normalized by N*(N-1)
malis_norm_type = none

# learning rate
eta = 0.01
# annealing factor
anneal_factor = 0.997
# number of iteration per learning rate annealing
Num_iter_per_annealing = 100
# momentum
momentum = 0.9
# weight decay
weight_decay = 0

# randomly transform patches to enrich training data, including rotation, fliping
is_data_aug = yes
# mirror the image region close to boundaries to get a full size output
is_bd_mirror = yes
# balance the boundary and non-boundary voxel
# global: compute the weight in the whole image stack
# patch: compute the balance weight for each patch
rebalance_mode = global

# standard IO format in Seunglab: https://docs.google.com/spreadsheets/d/1Frn-VH4VatqpwV96BTWSrtMQV0-9ej9soy6HXHgxWtc/edit?usp=sharing 
# if yes, will save the learning curve and network in one file
# if no, will save them separatly. This will be backward compatable.
# For new training, it is recommanded to use stdio
is_stdio = yes
# debug mode: yes, no
# if yes, will output some internal information and save patches in network file.
is_debug = no
# check the patches, used in Travis-ci for automatic test
is_check = no

# number of iteration per output
Num_iter_per_show = 100
# number of iteration per validation/test during training
Num_iter_per_test = 200
# number of forward pass of each test
test_num = 10
# number of iteration per save
Num_iter_per_save = 1000
# maximum iteration
Max_iter = 200000

# forward 
# sample ID for forward pass, example: 2-3,8
forward_range = 1
# forward network
forward_net = ../experiments/piriform/N4/net_current.h5
# forward convolution mode: fft, direct, optimize
# since optimization takes a long time, normally just use fft
forward_conv_mode = fft
# output size of one forward pass: z,y,x
# the larger the faster, limited by the memory capacity.
forward_outsz = 3,100,100
# output file name prefix
output_prefix = ../experiments/piriform/N4/out
